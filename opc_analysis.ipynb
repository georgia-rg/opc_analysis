{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-25T01:52:48.381084Z",
     "start_time": "2026-02-25T01:52:48.065738500Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "import os\n",
    "import io\n",
    "import matplotlib.ticker as ticker"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## OPC data import. Raw file information is: Dp in nm, time is in local time (PST) and the number concentrations are given not divided by the bin size (dlogDp) (check the README file for more info)",
   "id": "e90aa2c69437b09a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T01:52:51.883009600Z",
     "start_time": "2026-02-25T01:52:51.864865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths to OPC data files for the 3 different units\n",
    "path_unit2 = r'C:\\Users\\GeorgiaRg\\Documents\\ASCENT\\OPC\\Data-20260220T185711Z-1-001\\OPCdNcc_unit2.csv'\n",
    "path_unit4 = r'C:\\Users\\GeorgiaRg\\Documents\\ASCENT\\OPC\\Data-20260220T185711Z-1-001\\OPCdNcc_unit4.csv'\n",
    "path_unit8 = r'C:\\Users\\GeorgiaRg\\Documents\\ASCENT\\OPC\\Data-20260220T185711Z-1-001\\OPCdNcc_unit8.csv'\n",
    "\n",
    "# output_folder is the destination folder of all of the plots below\n",
    "output_dir = r'C:\\Users\\GeorgiaRg\\Documents\\ASCENT\\OPC\\Data-20260220T185711Z-1-001\\Output'"
   ],
   "id": "7940065957e99497",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T01:52:57.857262500Z",
     "start_time": "2026-02-25T01:52:54.007371800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_unit2 = pd.read_csv(path_unit2)\n",
    "df_unit4 = pd.read_csv(path_unit4)\n",
    "df_unit8 = pd.read_csv(path_unit8)\n",
    "df_unit2['local_time_pst'] = pd.to_datetime(df_unit2['local_time_pst'])\n",
    "df_unit4['local_time_pst'] = pd.to_datetime(df_unit4['local_time_pst'])\n",
    "df_unit8['local_time_pst'] = pd.to_datetime(df_unit8['local_time_pst'])"
   ],
   "id": "3da9b85618429c5e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Size distributions calculation (number, volume, mass-change particle density as needed)",
   "id": "a8bfc8fb3a58526b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T01:53:00.310870100Z",
     "start_time": "2026-02-25T01:52:59.501964100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Put the dataframes into a dictionary to loop through them\n",
    "units_data = {\n",
    "    'unit2': df_unit2,\n",
    "    'unit4': df_unit4,\n",
    "    'unit8': df_unit8\n",
    "}\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for unit_name, df in units_data.items():\n",
    "\n",
    "    # Extract bin boundaries (Dp) from column headers (300, 350, 400...)\n",
    "    # We exclude the 'local_time_pst' column\n",
    "    dp_boundaries = np.array([float(col) for col in df.columns if col != 'local_time_pst'])\n",
    "\n",
    "    # Since we need an upper bound for the last bin, estimate it\n",
    "    # by assuming the last step ratio is the same as the second to last.\n",
    "    last_ratio = dp_boundaries[-1] / dp_boundaries[-2]\n",
    "    dp_upper = np.append(dp_boundaries[1:], dp_boundaries[-1] * last_ratio)\n",
    "    dp_lower = dp_boundaries\n",
    "\n",
    "    # Calculate Bin Constants\n",
    "    dlogDp = np.log10(dp_upper) - np.log10(dp_lower)\n",
    "    dp_geo_mean = np.sqrt(dp_lower * dp_upper) # Geometric mean diameter\n",
    "\n",
    "    # Extract only the concentration data (the grid)\n",
    "    # Ensure we drop the time column properly\n",
    "    raw_counts = df.drop(columns=['local_time_pst']).values\n",
    "\n",
    "    # Calculate Distributions\n",
    "    # dN/dlogDp\n",
    "    dn_dlogdp = raw_counts / dlogDp\n",
    "\n",
    "    # dV/dlogDp (Dp is in nm, converting to um^3/cm^3)\n",
    "    # Volume of sphere = (pi/6) * D^3.\n",
    "    # Conversion: (nm^3) * 1e-9 = um^3\n",
    "    dv_dlogdp = dn_dlogdp * (np.pi / 6) * (dp_geo_mean**3) * 1e-9\n",
    "\n",
    "    # dM/dlogDp (Density = 1 g/cc = 1 ug/um^3) CHANGE DENSITY HERE IF NEEDED\n",
    "    dm_dlogdp = dv_dlogdp * 1.0\n",
    "\n",
    "    # Reconstruct into DataFrames for plotting\n",
    "    df_dn = pd.DataFrame(dn_dlogdp, columns=df.columns[df.columns != 'local_time_pst'], index=df['local_time_pst'])\n",
    "    df_dv = pd.DataFrame(dv_dlogdp, columns=df.columns[df.columns != 'local_time_pst'], index=df['local_time_pst'])\n",
    "    df_dm = pd.DataFrame(dm_dlogdp, columns=df.columns[df.columns != 'local_time_pst'], index=df['local_time_pst'])"
   ],
   "id": "ea35881539ca4b76",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Daily Average number and mass distributions into PP",
   "id": "60d7e9c9872878e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "    # Prep the Data\n",
    "    df_dn.index = pd.to_datetime(df_dn.index)\n",
    "    df_dm.index = pd.to_datetime(df_dm.index)\n",
    "\n",
    "    # Resample to DAILY Averages\n",
    "    daily_dn = df_dn.resample('D').mean().dropna(how='all')\n",
    "    daily_dm = df_dm.resample('D').mean().dropna(how='all')\n",
    "\n",
    "    # Initialize the PowerPoint Presentation\n",
    "    prs = Presentation()\n",
    "    blank_slide_layout = prs.slide_layouts[6]\n",
    "\n",
    "    # Plotting Loop & PowerPoint Generation\n",
    "    for day in daily_dn.index:\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "        day_str = day.strftime('%Y-%m-%d')\n",
    "\n",
    "        # --- Upper Plot: Number Distribution ---\n",
    "        ax1.plot(dp_geo_mean[:-1], daily_dn.loc[day].iloc[:-1], color='blue', lw=2, marker='o', markersize=4)\n",
    "        ax1.set_ylabel(r'$dN/d\\log D_p$ (#/cm$^3$)', fontsize=12)\n",
    "        ax1.set_title(f'[{unit_name.upper()}] Daily Aerosol Size Distribution: {day_str}', fontsize=14, fontweight='bold')\n",
    "        ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "\n",
    "        # --- Lower Plot: Mass Distribution ---\n",
    "        ax2.plot(dp_geo_mean[:-1], daily_dm.loc[day].iloc[:-1], color='red', lw=2, marker='s', markersize=4)\n",
    "        ax2.set_ylabel(r'$dM/d\\log D_p$ ($\\mu$g/m$^3$)', fontsize=12)\n",
    "        ax2.set_xlabel('Particle Diameter $D_p$ (nm)', fontsize=12)\n",
    "        ax2.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "\n",
    "        # --- Customizing the Logarithmic X-Axis Ticks ---\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.xaxis.set_major_locator(ticker.LogLocator(base=10.0, subs=(1.0, 2.0, 3.0, 4.0, 5.0, 7.0)))\n",
    "        formatter = ticker.ScalarFormatter()\n",
    "        formatter.set_scientific(False)\n",
    "        ax2.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "        plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure to an in-memory buffer\n",
    "        image_stream = io.BytesIO()\n",
    "        plt.savefig(image_stream, format='png', dpi=300)\n",
    "        plt.close(fig)\n",
    "        image_stream.seek(0)\n",
    "\n",
    "        # --- Add to PowerPoint ---\n",
    "        slide = prs.slides.add_slide(blank_slide_layout)\n",
    "        left = Inches(1.5)\n",
    "        top = Inches(0)\n",
    "        height = Inches(7.5)\n",
    "        slide.shapes.add_picture(image_stream, left, top, height=height)\n",
    "\n",
    "    # Save the Presentation specifically for this unit\n",
    "    ppt_filename = os.path.join(output_dir, f\"Daily_Distributions_Presentation_{unit_name}.pptx\")\n",
    "    prs.save(ppt_filename)\n",
    "\n",
    "    print(f\"Presentation for {unit_name} generated successfully. Saved to: {ppt_filename}\\n\")"
   ],
   "id": "c28cf747c8dc2008",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hourly Timeseries PM1, PM2.5, PM10",
   "id": "1bd287bfa9538616"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Put the dataframes into a dictionary for easy iteration\n",
    "units_data = {\n",
    "    'Unit 2': df_unit2,\n",
    "    'Unit 4': df_unit4,\n",
    "    'Unit 8': df_unit8\n",
    "}\n",
    "\n",
    "# Dictionaries to store the hourly averaged PM timeseries\n",
    "pm1_hourly = {}\n",
    "pm25_hourly = {}\n",
    "pm10_hourly = {}\n",
    "\n",
    "for unit_name, df in units_data.items():\n",
    "    if 'local_time_pst' in df.columns:\n",
    "        df_temp = df.set_index('local_time_pst')\n",
    "    else:\n",
    "        df_temp = df.copy()\n",
    "\n",
    "    df_temp.index = pd.to_datetime(df_temp.index)\n",
    "\n",
    "    # Extract bin boundaries (Dp)\n",
    "    dp_boundaries = np.array([float(col) for col in df_temp.columns])\n",
    "\n",
    "    last_ratio = dp_boundaries[-1] / dp_boundaries[-2]\n",
    "    dp_upper = np.append(dp_boundaries[1:], dp_boundaries[-1] * last_ratio)\n",
    "    dp_lower = dp_boundaries\n",
    "    dp_geo_mean = np.sqrt(dp_lower * dp_upper)\n",
    "\n",
    "    # Raw counts (dN) for each bin\n",
    "    raw_counts = df_temp.values\n",
    "\n",
    "    # Calculate dM for each bin\n",
    "    dM = raw_counts * (np.pi / 6) * (dp_geo_mean**3) * 1e-9 * 1.0\n",
    "    df_dM = pd.DataFrame(dM, columns=dp_boundaries, index=df_temp.index)\n",
    "\n",
    "    # Masks for PM1, PM2.5, PM10\n",
    "    mask_pm1 = dp_upper <= 1000\n",
    "    mask_pm25 = dp_upper <= 2500\n",
    "    mask_pm10 = dp_upper <= 10000\n",
    "\n",
    "    # Calculate raw sums for each timestep\n",
    "    # We replace 0 with np.nan here so that missing data doesn't artificially lower the hourly mean.\n",
    "    pm1_raw = df_dM.loc[:, mask_pm1].sum(axis=1).replace(0, np.nan)\n",
    "    pm25_raw = df_dM.loc[:, mask_pm25].sum(axis=1).replace(0, np.nan)\n",
    "    pm10_raw = df_dM.loc[:, mask_pm10].sum(axis=1).replace(0, np.nan)\n",
    "\n",
    "    # Resample to HOURLY averages ('h' stands for hourly). NaNs are automatically ignored.\n",
    "    pm1_hourly[unit_name] = pm1_raw.resample('h').mean().dropna()\n",
    "    pm25_hourly[unit_name] = pm25_raw.resample('h').mean().dropna()\n",
    "    pm10_hourly[unit_name] = pm10_raw.resample('h').mean().dropna()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3-Panel Plotting (Hourly Timeseries)\n",
    "# =========================================================\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n",
    "colors = {'Unit 2': 'blue', 'Unit 4': 'orange', 'Unit 8': 'green'}\n",
    "\n",
    "for unit_name in units_data.keys():\n",
    "    ax1.plot(pm1_hourly[unit_name].index, pm1_hourly[unit_name], label=unit_name, color=colors[unit_name], alpha=0.8, linewidth=2)\n",
    "    ax2.plot(pm25_hourly[unit_name].index, pm25_hourly[unit_name], label=unit_name, color=colors[unit_name], alpha=0.8, linewidth=2)\n",
    "    ax3.plot(pm10_hourly[unit_name].index, pm10_hourly[unit_name], label=unit_name, color=colors[unit_name], alpha=0.8, linewidth=2)\n",
    "\n",
    "# Format Top Panel\n",
    "ax1.set_ylabel(r'PM1 Mass ($\\mu$g/m$^3$)', fontsize=12)\n",
    "ax1.set_title('Hourly Averaged Particulate Matter (PM) Timeseries', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Format Middle Panel\n",
    "ax2.set_ylabel(r'PM2.5 Mass ($\\mu$g/m$^3$)', fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Format Bottom Panel\n",
    "ax3.set_ylabel(r'PM10 Mass ($\\mu$g/m$^3$)', fontsize=12)\n",
    "ax3.set_xlabel('Local Time (PST)', fontsize=12)\n",
    "ax3.legend(loc='upper right')\n",
    "ax3.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the timeseries plot\n",
    "ts_plot_path = os.path.join(output_dir, 'PM1_PM25_PM10_Hourly_Timeseries.png')\n",
    "plt.savefig(ts_plot_path, dpi=300)\n",
    "plt.show()"
   ],
   "id": "286347ce77a31ffc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Scatter plots between OPC units for hourly PM1, PM2.5, PM10",
   "id": "c49e8ea9c4467da1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "comparisons = [('Unit 2', 'Unit 4'), ('Unit 2', 'Unit 8'), ('Unit 4', 'Unit 8')]\n",
    "pm_metrics_hourly = [\n",
    "    ('PM1', pm1_hourly),\n",
    "    ('PM2.5', pm25_hourly),\n",
    "    ('PM10', pm10_hourly)\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "for row_idx, (pm_label, pm_dict) in enumerate(pm_metrics_hourly):\n",
    "    for col_idx, (unit_x, unit_y) in enumerate(comparisons):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "\n",
    "        series_x = pm_dict[unit_x]\n",
    "        series_y = pm_dict[unit_y]\n",
    "\n",
    "        # Combine them to ensure timestamps strictly align\n",
    "        df_compare = pd.concat([series_x, series_y], axis=1, join='inner').dropna()\n",
    "        df_compare.columns = [unit_x, unit_y]\n",
    "\n",
    "        # STRICT FILTER: Keep only rows where BOTH units have mass > 0\n",
    "        df_compare = df_compare[(df_compare[unit_x] > 0) & (df_compare[unit_y] > 0)]\n",
    "\n",
    "        # Scatter plot\n",
    "        ax.scatter(df_compare[unit_x], df_compare[unit_y], alpha=0.6, s=25, color='royalblue')\n",
    "\n",
    "        if not df_compare.empty:\n",
    "            # Extract x and y as numpy arrays for math\n",
    "            x_vals = df_compare[unit_x].values\n",
    "            y_vals = df_compare[unit_y].values\n",
    "\n",
    "            # Count the number of valid overlapping data points\n",
    "            n_points = len(x_vals)\n",
    "\n",
    "            # Calculate the best fit line y = a*x\n",
    "            a = np.sum(x_vals * y_vals) / np.sum(x_vals**2)\n",
    "\n",
    "            # Calculate R^2\n",
    "            y_pred = a * x_vals\n",
    "            ss_res = np.sum((y_vals - y_pred)**2)\n",
    "            ss_tot = np.sum((y_vals - np.mean(y_vals))**2)\n",
    "            r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "            # Determine plot limits to keep it square\n",
    "            min_val = min(x_vals.min(), y_vals.min())\n",
    "            max_val = max(x_vals.max(), y_vals.max())\n",
    "\n",
    "            # Add Padding\n",
    "            padding = (max_val - min_val) * 0.05\n",
    "            if padding == 0: padding = 1.0 # fallback if min equals max\n",
    "            min_lim = min_val - padding\n",
    "            max_lim = max_val + padding\n",
    "\n",
    "            ax.set_xlim(min_lim, max_lim)\n",
    "            ax.set_ylim(min_lim, max_lim)\n",
    "\n",
    "            # Plot the 1:1 reference line\n",
    "            ax.plot([min_lim, max_lim], [min_lim, max_lim], 'k--', alpha=0.5, label='1:1 line')\n",
    "\n",
    "            # Plot the y = a*x best-fit line, now adding n_points to the legend\n",
    "            line_x = np.array([0, max_lim])\n",
    "            line_y = a * line_x\n",
    "\n",
    "            # The label string below incorporates the equation, R^2, and n\n",
    "            legend_label = (rf'Fit: $y = {a:.2f}x$' + '\\n' +\n",
    "                            rf'$R^2 = {r_squared:.2f}$' + '\\n' +\n",
    "                            rf'$n = {n_points}$')\n",
    "\n",
    "            ax.plot(line_x, line_y, color='red', linestyle='-', linewidth=2, label=legend_label)\n",
    "\n",
    "        ax.set_title(rf'Hourly {pm_label}: {unit_x} vs {unit_y}', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel(rf'{unit_x} ($\\mu$g/m$^3$)', fontsize=10)\n",
    "        ax.set_ylabel(rf'{unit_y} ($\\mu$g/m$^3$)', fontsize=10)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Enable the legend on ALL subplots\n",
    "        ax.legend(loc='upper left', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the scatter plot\n",
    "scatter_plot_path = os.path.join(output_dir, 'Scatter_Plots_Hourly_Comparison_with_Fit.png')\n",
    "plt.savefig(scatter_plot_path, dpi=300)\n",
    "plt.show()"
   ],
   "id": "a5a413b7c479086d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import SMPS data",
   "id": "e080ff63a9d01c5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T01:53:13.957223900Z",
     "start_time": "2026-02-25T01:53:13.645474300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Update this path to match exactly where you exported the SMPS file.\n",
    "# If you moved it to the output_dir defined in cell 2 of this notebook, you can use:\n",
    "import_path = r'C:\\Users\\GeorgiaRg\\Documents\\ASCENT\\SMPS\\Cleaned from Puru\\Output\\hourly_dMdlogDp_distribution.csv'\n",
    "\n",
    "# Import the CSV\n",
    "# index_col=0 restores the timestamps as the row index\n",
    "# parse_dates=True converts the index back into datetime objects\n",
    "hourly_dMdlogDp_smps = pd.read_csv(import_path, index_col=0, parse_dates=True)\n",
    "\n",
    "# Convert the column headers (diameter bins) back to floats\n",
    "# This matches how the OPC data columns are treated in this notebook\n",
    "hourly_dMdlogDp_smps.columns = [float(col) for col in hourly_dMdlogDp_smps.columns]\n",
    "\n",
    "# View the imported dataframe\n",
    "display(hourly_dMdlogDp_smps.head())"
   ],
   "id": "20f682cfec2702b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             13.10     13.58     14.07     14.59     15.12   \\\n",
       "sample_datetime_local                                                         \n",
       "2023-08-04 13:00:00-07:00  0.001925  0.002286  0.003500  0.004282  0.005274   \n",
       "2023-08-04 14:00:00-07:00  0.002638  0.003928  0.005466  0.006828  0.009713   \n",
       "2023-08-04 15:00:00-07:00  0.004233  0.006262  0.008858  0.012612  0.017624   \n",
       "2023-08-04 16:00:00-07:00  0.004717  0.007386  0.010373  0.014400  0.018316   \n",
       "2023-08-04 17:00:00-07:00  0.014516  0.019836  0.025270  0.032881  0.040894   \n",
       "\n",
       "                             15.68     16.25     16.85     17.47     18.11   \\\n",
       "sample_datetime_local                                                         \n",
       "2023-08-04 13:00:00-07:00  0.006277  0.008319  0.010214  0.012657  0.015920   \n",
       "2023-08-04 14:00:00-07:00  0.012268  0.015133  0.020926  0.027252  0.033999   \n",
       "2023-08-04 15:00:00-07:00  0.023955  0.031418  0.039273  0.052593  0.063943   \n",
       "2023-08-04 16:00:00-07:00  0.025860  0.033695  0.043334  0.055116  0.068804   \n",
       "2023-08-04 17:00:00-07:00  0.050691  0.062422  0.075810  0.090094  0.104846   \n",
       "\n",
       "                           ...    572.55     593.52     615.27     637.80  \\\n",
       "sample_datetime_local      ...                                              \n",
       "2023-08-04 13:00:00-07:00  ...  5.988544   8.430783   5.343030  11.039085   \n",
       "2023-08-04 14:00:00-07:00  ...  9.603036  10.055131  10.986470   8.750395   \n",
       "2023-08-04 15:00:00-07:00  ...  7.238151   6.981961  10.085579  12.127098   \n",
       "2023-08-04 16:00:00-07:00  ...  6.782234   9.058732   7.991994   9.749827   \n",
       "2023-08-04 17:00:00-07:00  ...  8.136897   7.981696   8.062204   8.458184   \n",
       "\n",
       "                              661.17     685.39     710.50     736.53  \\\n",
       "sample_datetime_local                                                   \n",
       "2023-08-04 13:00:00-07:00   8.298336  11.593794   9.427108  18.099605   \n",
       "2023-08-04 14:00:00-07:00  10.704494  11.294113  13.065447  19.202703   \n",
       "2023-08-04 15:00:00-07:00  12.835171  12.872214   9.255497  14.652886   \n",
       "2023-08-04 16:00:00-07:00  13.617746  12.982889  11.304206  11.491447   \n",
       "2023-08-04 17:00:00-07:00  10.152345  10.892734  12.370799  14.644725   \n",
       "\n",
       "                              763.51     791.48  \n",
       "sample_datetime_local                            \n",
       "2023-08-04 13:00:00-07:00  12.184571  19.032505  \n",
       "2023-08-04 14:00:00-07:00  20.843615  16.929775  \n",
       "2023-08-04 15:00:00-07:00  14.584289  18.879826  \n",
       "2023-08-04 16:00:00-07:00  13.718661  19.996334  \n",
       "2023-08-04 17:00:00-07:00  11.360623  15.236181  \n",
       "\n",
       "[5 rows x 115 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>13.10</th>\n",
       "      <th>13.58</th>\n",
       "      <th>14.07</th>\n",
       "      <th>14.59</th>\n",
       "      <th>15.12</th>\n",
       "      <th>15.68</th>\n",
       "      <th>16.25</th>\n",
       "      <th>16.85</th>\n",
       "      <th>17.47</th>\n",
       "      <th>18.11</th>\n",
       "      <th>...</th>\n",
       "      <th>572.55</th>\n",
       "      <th>593.52</th>\n",
       "      <th>615.27</th>\n",
       "      <th>637.80</th>\n",
       "      <th>661.17</th>\n",
       "      <th>685.39</th>\n",
       "      <th>710.50</th>\n",
       "      <th>736.53</th>\n",
       "      <th>763.51</th>\n",
       "      <th>791.48</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_datetime_local</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-08-04 13:00:00-07:00</th>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.012657</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>...</td>\n",
       "      <td>5.988544</td>\n",
       "      <td>8.430783</td>\n",
       "      <td>5.343030</td>\n",
       "      <td>11.039085</td>\n",
       "      <td>8.298336</td>\n",
       "      <td>11.593794</td>\n",
       "      <td>9.427108</td>\n",
       "      <td>18.099605</td>\n",
       "      <td>12.184571</td>\n",
       "      <td>19.032505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-04 14:00:00-07:00</th>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.012268</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.027252</td>\n",
       "      <td>0.033999</td>\n",
       "      <td>...</td>\n",
       "      <td>9.603036</td>\n",
       "      <td>10.055131</td>\n",
       "      <td>10.986470</td>\n",
       "      <td>8.750395</td>\n",
       "      <td>10.704494</td>\n",
       "      <td>11.294113</td>\n",
       "      <td>13.065447</td>\n",
       "      <td>19.202703</td>\n",
       "      <td>20.843615</td>\n",
       "      <td>16.929775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-04 15:00:00-07:00</th>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.008858</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>0.017624</td>\n",
       "      <td>0.023955</td>\n",
       "      <td>0.031418</td>\n",
       "      <td>0.039273</td>\n",
       "      <td>0.052593</td>\n",
       "      <td>0.063943</td>\n",
       "      <td>...</td>\n",
       "      <td>7.238151</td>\n",
       "      <td>6.981961</td>\n",
       "      <td>10.085579</td>\n",
       "      <td>12.127098</td>\n",
       "      <td>12.835171</td>\n",
       "      <td>12.872214</td>\n",
       "      <td>9.255497</td>\n",
       "      <td>14.652886</td>\n",
       "      <td>14.584289</td>\n",
       "      <td>18.879826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-04 16:00:00-07:00</th>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.007386</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.025860</td>\n",
       "      <td>0.033695</td>\n",
       "      <td>0.043334</td>\n",
       "      <td>0.055116</td>\n",
       "      <td>0.068804</td>\n",
       "      <td>...</td>\n",
       "      <td>6.782234</td>\n",
       "      <td>9.058732</td>\n",
       "      <td>7.991994</td>\n",
       "      <td>9.749827</td>\n",
       "      <td>13.617746</td>\n",
       "      <td>12.982889</td>\n",
       "      <td>11.304206</td>\n",
       "      <td>11.491447</td>\n",
       "      <td>13.718661</td>\n",
       "      <td>19.996334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-04 17:00:00-07:00</th>\n",
       "      <td>0.014516</td>\n",
       "      <td>0.019836</td>\n",
       "      <td>0.025270</td>\n",
       "      <td>0.032881</td>\n",
       "      <td>0.040894</td>\n",
       "      <td>0.050691</td>\n",
       "      <td>0.062422</td>\n",
       "      <td>0.075810</td>\n",
       "      <td>0.090094</td>\n",
       "      <td>0.104846</td>\n",
       "      <td>...</td>\n",
       "      <td>8.136897</td>\n",
       "      <td>7.981696</td>\n",
       "      <td>8.062204</td>\n",
       "      <td>8.458184</td>\n",
       "      <td>10.152345</td>\n",
       "      <td>10.892734</td>\n",
       "      <td>12.370799</td>\n",
       "      <td>14.644725</td>\n",
       "      <td>11.360623</td>\n",
       "      <td>15.236181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 115 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
